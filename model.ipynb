{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rt</th>\n",
       "      <th>amp</th>\n",
       "      <th>trash</th>\n",
       "      <th>hoe</th>\n",
       "      <th>fuck</th>\n",
       "      <th>bitch</th>\n",
       "      <th>shit</th>\n",
       "      <th>like</th>\n",
       "      <th>hoes</th>\n",
       "      <th>got</th>\n",
       "      <th>...</th>\n",
       "      <th>lol</th>\n",
       "      <th>nigga</th>\n",
       "      <th>dont</th>\n",
       "      <th>pussy</th>\n",
       "      <th>aint</th>\n",
       "      <th>ass</th>\n",
       "      <th>know</th>\n",
       "      <th>orig_tweets</th>\n",
       "      <th>sentiment_value</th>\n",
       "      <th>class_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.851285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rt mleew17 boy dats coldtyga dwn bad cuffin da...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    rt  amp  trash  hoe  fuck  bitch  shit  like  hoes       got  ...  lol  \\\n",
       "0  0.0  0.0    0.0  0.0   0.0    0.0   0.0   0.0   0.0  0.851285  ...  0.0   \n",
       "\n",
       "   nigga  dont  pussy      aint  ass  know  \\\n",
       "0    0.0   0.0    0.0  0.524704  0.0   0.0   \n",
       "\n",
       "                                         orig_tweets  sentiment_value  \\\n",
       "0  rt mleew17 boy dats coldtyga dwn bad cuffin da...                0   \n",
       "\n",
       "   class_value  \n",
       "0            1  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "\n",
    "file = \"Datasets/PreProcessed/dataset1Finalisedcol23.csv\"\n",
    "\n",
    "# Counting number of rows in dataset\n",
    "n = sum(1 for line in open(file))-1\n",
    "\n",
    "# Getting a sample size of 5%\n",
    "s = n//5\n",
    "\n",
    "skip = sorted(random.sample(range(1, n+1), n-s))\n",
    "\n",
    "df = pd.read_csv(file, skiprows=skip)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "\n",
    "x = df.drop([\"class_value\", 'orig_tweets', 'sentiment_value'], axis=1)\n",
    "y = df[\"class_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jakeh\\Documents\\Computing\\Hate Speech Detection\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\jakeh\\Documents\\Computing\\Hate Speech Detection\\.venv\\Lib\\site-packages\\keras\\src\\losses\\losses.py:27: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m992/992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 396us/step - accuracy: 0.7812 - loss: 0.0000e+00\n",
      "Epoch 2/10\n",
      "\u001b[1m992/992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7800 - loss: 0.0000e+00\n",
      "Epoch 3/10\n",
      "\u001b[1m992/992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7739 - loss: 0.0000e+00\n",
      "Epoch 4/10\n",
      "\u001b[1m992/992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7799 - loss: 0.0000e+00\n",
      "Epoch 5/10\n",
      "\u001b[1m992/992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7847 - loss: 0.0000e+00\n",
      "Epoch 6/10\n",
      "\u001b[1m992/992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7705 - loss: 0.0000e+00\n",
      "Epoch 7/10\n",
      "\u001b[1m992/992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7808 - loss: 0.0000e+00\n",
      "Epoch 8/10\n",
      "\u001b[1m992/992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.7787 - loss: 0.0000e+00\n",
      "Epoch 9/10\n",
      "\u001b[1m992/992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7706 - loss: 0.0000e+00\n",
      "Epoch 10/10\n",
      "\u001b[1m992/992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.7774 - loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x197891cc050>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the model layers\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_shape=(20,), activation=\"sigmoid\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# compile model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adamax\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit model\n",
    "model.fit(x, y, epochs=10, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - accuracy: 0.7648 - loss: 0.0000e+00\n",
      "Accuracy: 77.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jakeh\\Documents\\Computing\\Hate Speech Detection\\.venv\\Lib\\site-packages\\keras\\src\\losses\\losses.py:27: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Evaluting the model\n",
    "_, accuracy = model.evaluate(x, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
